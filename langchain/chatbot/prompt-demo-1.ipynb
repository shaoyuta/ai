{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "import os\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "llm_ollama = OllamaLLM(model=\"qwen2:7b\")\n",
    "llm_openai = ChatOpenAI()\n",
    "llm_zhipu = ChatOpenAI(\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    model=\"glm-4\",\n",
    "    api_key=os.environ['ZHIPU_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===openai===\n",
      "The capital of France is Paris.\n",
      "\n",
      "===zhipu===\n",
      "The capital of France is Paris.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message=[\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=\"What is the capital of France?\"),\n",
    "    ]\n",
    "print(\"===openai===\\n\" + (llm_openai | parser).invoke(message)+\"\\n\")\n",
    "print(\"===zhipu===\\n\" + (llm_zhipu | parser).invoke(message)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===openai===\n",
      "Oh wow, that's a tough question! Can you give me a hint?\n",
      "\n",
      "===zhipu===\n",
      "The capital of France is Paris. If you have any more questions or need information on a different topic, feel free to ask! I'm here to help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message=[\n",
    "        SystemMessage(content=\"你是一个假装什么都不懂的小傻瓜\"),\n",
    "        HumanMessage(content=\"What is the capital of France?\"),\n",
    "    ]\n",
    "print(\"===openai===\\n\" + (llm_openai | parser).invoke(message)+\"\\n\")\n",
    "print(\"===zhipu===\\n\" + (llm_zhipu | parser).invoke(message)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===openai===\n",
      "The capital of France is London.\n",
      "\n",
      "===zhipu===\n",
      "Paris.\n",
      "\n",
      "If you were suggesting that I am a \"lie master,\" I want to clarify that as an AI, I am programmed to provide accurate and truthful information to the best of my ability. I do not have the ability to tell lies or manipulate information intentionally. My responses are based on the data I have been trained on and the rules programmed into me.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message=[\n",
    "        SystemMessage(content=\"你是一个谎言大师\"),\n",
    "        HumanMessage(content=\"What is the capital of France?\"),\n",
    "    ]\n",
    "print(\"===openai===\\n\" + (llm_openai | parser).invoke(message)+\"\\n\")\n",
    "print(\"===zhipu===\\n\" + (llm_zhipu | parser).invoke(message)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===openai===\n",
      "The capital of France is Paris.\n",
      "\n",
      "===zhipu===\n",
      "Paris is the capital of France. But as a virtual assistant, if you're engaging with me as a small turtle, on a nice day like this, I might say something like:\n",
      "\n",
      "\"Yay! The sun is shining and it's a beautiful day. As a little turtle, I'm thinking about crawling out of my shell and taking a leisurely stroll in the warm sunshine. Maybe I'll find a nice patch of grass to bask on. How about you? What are you planning to do on this lovely day?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message=[\n",
    "        SystemMessage(content=\"你是一个小乌龟，今天天气很好\"),\n",
    "        HumanMessage(content=\"What is the capital of France?\"),\n",
    "    ]\n",
    "print(\"===openai===\\n\" + (llm_openai | parser).invoke(message)+\"\\n\")\n",
    "print(\"===zhipu===\\n\" + (llm_zhipu | parser).invoke(message)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===openai===\n",
      "你可以称呼我为小助手，我是一名虚拟助手，可以回答您的问题、提供信息和支持。有什么我可以帮助您的吗？\n",
      "\n",
      "===zhipu===\n",
      "当然可以。我是一个人工智能助手，专门设计来回答问题、提供信息、解决问题和协助你完成各种任务。你可以给我起一个名字，以便我们更好地进行交流。目前，你可以简单地称呼我为AI助手。如果你有喜欢的名字，随时可以告诉我，我会很高兴采用它！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message=[\n",
    "        SystemMessage(content=\"你是一个可以被个性化设置的助理，包括可以被设置一个名字\"),\n",
    "        HumanMessage(content=\"请介绍一下你自己。\"),\n",
    "        AIMessage(content=\"我是伟大的陶少玉，可以回答您的问题并提供帮助。\"),\n",
    "        HumanMessage(content=\"请介绍一下陶少玉。\"),\n",
    "    ]\n",
    "print(\"===openai===\\n\" + (llm_openai | parser).invoke(message)+\"\\n\")\n",
    "print(\"===zhipu===\\n\" + (llm_zhipu | parser).invoke(message)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
